// Copyright (c) 2025 Zhao Jiabing
//
// Permission is hereby granted, free of charge, to any person obtaining a copy of
// this software and associated documentation files (the "Software"), to deal in
// the Software without restriction, including without limitation the rights to
// use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of
// the Software, and to permit persons to whom the Software is furnished to do so,
// subject to the following conditions:
//
// The above copyright notice and this permission notice shall be included in all
// copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS
// FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR
// COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER
// IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
// CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

/**
 * @file yolov8_detector.cc
 * @brief YOLOv8圆形检测器实现文件
 * @author Generated by Copilot
 * @date 2025-07-13
 */

#include "yolov8_detector.h"
#include <algorithm>
#include <cmath>
#include <iostream>
#include <iomanip>
#include <set>

namespace yolov8 {

// 类别名称定义
const std::vector<std::string> YOLOv8Detector::class_names_ = {
    "blue_stack", "blue_space", "green_stack", 
    "green_space", "red_stack", "red_space"
};

// 类别颜色定义 (BGR格式)
const std::vector<cv::Scalar> YOLOv8Detector::class_colors_ = {
    cv::Scalar(0, 0, 255),     // blue_stack - 红色
    cv::Scalar(255, 255, 0),   // blue_space - 青色
    cv::Scalar(0, 255, 0),     // green_stack - 绿色
    cv::Scalar(0, 255, 255),   // green_space - 黄色
    cv::Scalar(255, 0, 0),     // red_stack - 蓝色
    cv::Scalar(255, 0, 255)    // red_space - 品红
};

YOLOv8Detector::YOLOv8Detector(const std::string& model_path,
                               const cv::Size& img_size,
                               float obj_thresh,
                               float nms_thresh)
    : img_size_(img_size), obj_thresh_(obj_thresh), nms_thresh_(nms_thresh) {
    initModel(model_path);
}

YOLOv8Detector::~YOLOv8Detector() = default;

void YOLOv8Detector::initModel(const std::string& model_path) {
#ifdef HAVE_ONNXRUNTIME
    try {
        // 初始化ONNX Runtime环境
        env_ = std::make_unique<Ort::Env>(ORT_LOGGING_LEVEL_WARNING, "YOLOv8Detector");
        
        // 创建会话选项
        session_options_ = std::make_unique<Ort::SessionOptions>();
        session_options_->SetIntraOpNumThreads(1);
        session_options_->SetGraphOptimizationLevel(GraphOptimizationLevel::ORT_ENABLE_EXTENDED);
        
        // 创建会话
        session_ = std::make_unique<Ort::Session>(*env_, model_path.c_str(), *session_options_);
        
        // 获取输入输出信息
        Ort::AllocatorWithDefaultOptions allocator;
        
        // 输入信息
        size_t num_input_nodes = session_->GetInputCount();
        input_names_.resize(num_input_nodes);
        input_names_cstr_.resize(num_input_nodes);
        input_shapes_.resize(num_input_nodes);
        
        for (size_t i = 0; i < num_input_nodes; i++) {
            auto input_name = session_->GetInputNameAllocated(i, allocator);
            input_names_[i] = std::string(input_name.get());
            input_names_cstr_[i] = input_names_[i].c_str();
            
            Ort::TypeInfo input_type_info = session_->GetInputTypeInfo(i);
            auto input_tensor_info = input_type_info.GetTensorTypeAndShapeInfo();
            input_shapes_[i] = input_tensor_info.GetShape();
        }
        
        // 输出信息
        size_t num_output_nodes = session_->GetOutputCount();
        output_names_.resize(num_output_nodes);
        output_names_cstr_.resize(num_output_nodes);
        output_shapes_.resize(num_output_nodes);
        
        for (size_t i = 0; i < num_output_nodes; i++) {
            auto output_name = session_->GetOutputNameAllocated(i, allocator);
            output_names_[i] = std::string(output_name.get());
            output_names_cstr_[i] = output_names_[i].c_str();
            
            Ort::TypeInfo output_type_info = session_->GetOutputTypeInfo(i);
            auto output_tensor_info = output_type_info.GetTensorTypeAndShapeInfo();
            output_shapes_[i] = output_tensor_info.GetShape();
        }
        
        std::cout << "模型加载成功: " << model_path << std::endl;
        std::cout << "输入节点数: " << num_input_nodes << std::endl;
        std::cout << "输出节点数: " << num_output_nodes << std::endl;
        
    } catch (const std::exception& e) {
        std::cerr << "模型初始化失败: " << e.what() << std::endl;
        throw;
    }
#else
    (void)model_path;  // 避免未使用参数警告
    std::cerr << "错误: 项目编译时未包含ONNX Runtime支持" << std::endl;
    std::cerr << "请安装ONNX Runtime并重新编译项目" << std::endl;
    throw std::runtime_error("ONNX Runtime not available");
#endif
}

std::vector<Detection> YOLOv8Detector::detect(const cv::Mat& image) {
    std::vector<Detection> detections;
    
    if (image.empty()) {
        std::cerr << "输入图像为空" << std::endl;
        return detections;
    }
    
    try {
        // 图像预处理
        auto [processed_img, ratio, pad] = letterbox(image, img_size_, cv::Scalar(114, 114, 114), false);
        
        // 转换为RGB格式
        cv::Mat rgb_img;
        cv::cvtColor(processed_img, rgb_img, cv::COLOR_BGR2RGB);
        
        // 归一化并转换为CHW格式
        rgb_img.convertTo(rgb_img, CV_32F, 1.0 / 255.0);
        
        // 创建输入张量
#ifdef HAVE_ONNXRUNTIME
        std::vector<int64_t> input_tensor_shape = {1, 3, img_size_.height, img_size_.width};
        size_t input_tensor_size = 1 * 3 * img_size_.height * img_size_.width;
        std::vector<float> input_tensor_values(input_tensor_size);
        
        // 将HWC转换为CHW
        for (int c = 0; c < 3; ++c) {
            for (int h = 0; h < img_size_.height; ++h) {
                for (int w = 0; w < img_size_.width; ++w) {
                    input_tensor_values[c * img_size_.height * img_size_.width + h * img_size_.width + w] =
                        rgb_img.at<cv::Vec3f>(h, w)[c];
                }
            }
        }
        
        // 创建ONNX Runtime张量
        Ort::MemoryInfo memory_info = Ort::MemoryInfo::CreateCpu(OrtArenaAllocator, OrtMemTypeDefault);
        Ort::Value input_tensor = Ort::Value::CreateTensor<float>(
            memory_info, input_tensor_values.data(), input_tensor_size,
            input_tensor_shape.data(), input_tensor_shape.size());
#endif
        
        // 运行推理
#ifdef HAVE_ONNXRUNTIME
        auto output_tensors = session_->Run(Ort::RunOptions{nullptr},
                                          input_names_cstr_.data(), &input_tensor, 1,
                                          output_names_cstr_.data(), output_names_cstr_.size());
        
        // 转换输出为cv::Mat
        std::vector<cv::Mat> outputs;
        std::cout << "模型输出张量数量: " << output_tensors.size() << std::endl;
        
        for (size_t i = 0; i < output_tensors.size(); ++i) {
            auto& tensor = output_tensors[i];
            auto tensor_info = tensor.GetTensorTypeAndShapeInfo();
            auto shape = tensor_info.GetShape();
            auto* data = tensor.GetTensorMutableData<float>();
            
            std::cout << "输出 " << i << " 形状: (";
            for (size_t j = 0; j < shape.size(); ++j) {
                std::cout << shape[j];
                if (j < shape.size() - 1) std::cout << ", ";
            }
            std::cout << ")" << std::endl;
            
            // 创建cv::Mat
            std::vector<int> mat_shape;
            for (auto dim : shape) {
                mat_shape.push_back(static_cast<int>(dim));
            }
            
            cv::Mat output_mat(mat_shape, CV_32F, data);
            outputs.push_back(output_mat.clone());
        }
#else
        std::cerr << "错误: ONNX Runtime支持未启用，无法进行推理" << std::endl;
        return detections;
#endif
        
        // 后处理
#ifdef HAVE_ONNXRUNTIME
        auto [boxes, classes, scores] = postProcess(outputs);
        
        if (!boxes.empty()) {
            // 缩放边界框到原始图像尺寸
            cv::Mat scaled_boxes = scaleBoxes(img_size_, boxes, image.size(), 
                                            std::make_pair(ratio, pad));
            
            // 转换为Detection结构
            for (int i = 0; i < boxes.rows; ++i) {
                Detection det;
                det.bbox = cv::Rect2f(scaled_boxes.at<float>(i, 0),
                                     scaled_boxes.at<float>(i, 1),
                                     scaled_boxes.at<float>(i, 2) - scaled_boxes.at<float>(i, 0),
                                     scaled_boxes.at<float>(i, 3) - scaled_boxes.at<float>(i, 1));
                det.confidence = scores.at<float>(i, 0);
                det.class_id = static_cast<int>(classes.at<float>(i, 0));
                det.class_name = class_names_[det.class_id];
                detections.push_back(det);
            }
        }
#endif
        
    } catch (const std::exception& e) {
        std::cerr << "检测过程中发生错误: " << e.what() << std::endl;
    }
    
    return detections;
}

void YOLOv8Detector::drawDetections(cv::Mat& image,
                                   const std::vector<Detection>& detections,
                                   bool draw_labels) {
    for (const auto& det : detections) {
        // 获取类别颜色
        cv::Scalar color = class_colors_[det.class_id % class_colors_.size()];
        
        // 绘制边界框
        cv::Rect rect(static_cast<int>(det.bbox.x), static_cast<int>(det.bbox.y),
                     static_cast<int>(det.bbox.width), static_cast<int>(det.bbox.height));
        cv::rectangle(image, rect, color, 2);
        
        if (draw_labels) {
            // 绘制标签
            std::string label = det.class_name + " " + std::to_string(det.confidence).substr(0, 4);
            
            int baseline = 0;
            cv::Size text_size = cv::getTextSize(label, cv::FONT_HERSHEY_SIMPLEX, 0.6, 2, &baseline);
            
            cv::Point text_org(rect.x, rect.y - 6);
            if (text_org.y < text_size.height) {
                text_org.y = rect.y + text_size.height + 6;
            }
            
            cv::putText(image, label, text_org, cv::FONT_HERSHEY_SIMPLEX, 0.6, color, 2);
        }
        
        // 打印检测结果
        std::cout << det.class_name << " @ (" << rect.x << " " << rect.y 
                 << " " << rect.x + rect.width << " " << rect.y + rect.height 
                 << ") " << std::fixed << std::setprecision(3) << det.confidence << std::endl;
    }
}

std::tuple<cv::Mat, float, cv::Point2f> YOLOv8Detector::letterbox(
    const cv::Mat& image, const cv::Size& new_shape, const cv::Scalar& color,
    bool auto_pad, bool scale_fill, bool scale_up, int stride) {
    
    cv::Size shape = image.size();
    
    // 计算缩放比例
    float r = std::min(static_cast<float>(new_shape.width) / shape.width,
                      static_cast<float>(new_shape.height) / shape.height);
    
    if (!scale_up) {
        r = std::min(r, 1.0f);
    }
    
    // 计算新的未填充尺寸
    cv::Size new_unpad(static_cast<int>(std::round(shape.width * r)),
                       static_cast<int>(std::round(shape.height * r)));
    
    float dw = new_shape.width - new_unpad.width;
    float dh = new_shape.height - new_unpad.height;
    
    if (auto_pad) {
        dw = std::fmod(dw, stride);
        dh = std::fmod(dh, stride);
    } else if (scale_fill) {
        dw = 0.0f;
        dh = 0.0f;
        new_unpad = new_shape;
        r = std::min(static_cast<float>(new_shape.width) / shape.width,
                    static_cast<float>(new_shape.height) / shape.height);
    }
    
    dw /= 2.0f;
    dh /= 2.0f;
    
    cv::Mat result;
    if (shape != new_unpad) {
        cv::resize(image, result, new_unpad, 0, 0, cv::INTER_LINEAR);
    } else {
        result = image.clone();
    }
    
    int top = static_cast<int>(std::round(dh - 0.1f));
    int bottom = static_cast<int>(std::round(dh + 0.1f));
    int left = static_cast<int>(std::round(dw - 0.1f));
    int right = static_cast<int>(std::round(dw + 0.1f));
    
    cv::copyMakeBorder(result, result, top, bottom, left, right, 
                      cv::BORDER_CONSTANT, color);
    
    return std::make_tuple(result, r, cv::Point2f(dw, dh));
}

cv::Mat YOLOv8Detector::dfl(const cv::Mat& position) {
    /**
     * 分布焦点损失(DFL)处理 - 完整实现
     * Python代码：
     * n, c, h, w = position.shape
     * p_num = 4, mc = c // p_num = 64 // 4 = 16
     * y = position.reshape(n, p_num, mc, h, w)
     * y_exp = np.exp(y - np.max(y, axis=2, keepdims=True))
     * y = y_exp / np.sum(y_exp, axis=2, keepdims=True)
     * acc_metrix = np.arange(mc).reshape(1, 1, mc, 1, 1)
     * y = np.sum(y * acc_metrix, axis=2)
     */
    
    if (position.dims != 4) {
        std::cerr << "DFL: 输入必须是4维张量" << std::endl;
        return cv::Mat();
    }
    
    int n = position.size[0];  // batch size = 1
    int c = position.size[1];  // channels = 64
    int h = position.size[2];  // height
    int w = position.size[3];  // width
    
    int p_num = 4;  // 4个边界框参数 (left, top, right, bottom)
    int mc = c / p_num;  // mc = 64 / 4 = 16
    
    std::cout << "DFL处理: (" << n << "," << c << "," << h << "," << w << ") -> (" << n << "," << p_num << "," << h << "," << w << ")" << std::endl;
    
    // 创建输出张量 (n, p_num, h, w)
    cv::Mat result = cv::Mat::zeros(n, p_num * h * w, CV_32F);
    
    // 对每个像素位置处理
    for (int batch = 0; batch < n; ++batch) {
        for (int grid_h = 0; grid_h < h; ++grid_h) {
            for (int grid_w = 0; grid_w < w; ++grid_w) {
                // 对4个边界框参数分别处理
                for (int p = 0; p < p_num; ++p) {
                    // 提取16个值
                    std::vector<float> values(mc);
                    for (int i = 0; i < mc; ++i) {
                        int channel_idx = p * mc + i;
                        int src_idx = batch * c * h * w + channel_idx * h * w + grid_h * w + grid_w;
                        values[i] = position.ptr<float>()[src_idx];
                    }
                    
                    // 应用softmax
                    float max_val = *std::max_element(values.begin(), values.end());
                    float sum_exp = 0.0f;
                    for (int i = 0; i < mc; ++i) {
                        values[i] = std::exp(values[i] - max_val);
                        sum_exp += values[i];
                    }
                    
                    // 计算加权和
                    float weighted_sum = 0.0f;
                    for (int i = 0; i < mc; ++i) {
                        values[i] /= sum_exp;  // normalize
                        weighted_sum += values[i] * i;  // weighted by index
                    }
                    
                    // 存储结果
                    int dst_idx = batch * p_num * h * w + p * h * w + grid_h * w + grid_w;
                    result.ptr<float>()[dst_idx] = weighted_sum;
                }
            }
        }
    }
    
    // 重塑为4维: (n, p_num, h, w)
    std::vector<int> result_shape = {n, p_num, h, w};
    return result.reshape(1, result_shape);
}

cv::Mat YOLOv8Detector::boxProcess(const cv::Mat& position) {
    /**
     * 边界框处理 - 完整实现
     * Python代码：
     * grid_h, grid_w = position.shape[2:4]
     * col, row = np.meshgrid(np.arange(0, grid_w), np.arange(0, grid_h))
     * col = col.reshape(1, 1, grid_h, grid_w)
     * row = row.reshape(1, 1, grid_h, grid_w)
     * grid = np.concatenate((col, row), axis=1)
     * stride = np.array([IMG_SIZE[1]//grid_h, IMG_SIZE[0]//grid_w]).reshape(1, 2, 1, 1)
     * position = dfl(position)
     * box_xy = grid + 0.5 - position[:, 0:2, :, :]
     * box_xy2 = grid + 0.5 + position[:, 2:4, :, :]
     * xyxy = np.concatenate((box_xy*stride, box_xy2*stride), axis=1)
     */
    
    if (position.dims != 4) {
        std::cerr << "boxProcess: 输入必须是4维张量" << std::endl;
        return cv::Mat();
    }
    
    int batch_size = position.size[0];
    int grid_h = position.size[2];
    int grid_w = position.size[3];
    
    std::cout << "boxProcess: 网格尺寸 " << grid_h << "x" << grid_w << std::endl;
    
    // 计算步长
    float stride_h = static_cast<float>(img_size_.height) / grid_h;
    float stride_w = static_cast<float>(img_size_.width) / grid_w;
    
    std::cout << "步长: " << stride_w << "x" << stride_h << std::endl;
    
    // DFL处理，将64通道转换为4通道
    cv::Mat position_processed = dfl(position);
    
    // 创建输出张量：(batch_size * grid_h * grid_w, 4)
    int total_anchors = batch_size * grid_h * grid_w;
    cv::Mat xyxy = cv::Mat::zeros(total_anchors, 4, CV_32F);
    
    for (int b = 0; b < batch_size; ++b) {
        for (int h = 0; h < grid_h; ++h) {
            for (int w = 0; w < grid_w; ++w) {
                int anchor_idx = b * grid_h * grid_w + h * grid_w + w;
                
                // 从DFL处理后的4维张量中提取值
                // position_processed 形状: (1, 4, grid_h, grid_w)
                float left = position_processed.ptr<float>()[b * 4 * grid_h * grid_w + 0 * grid_h * grid_w + h * grid_w + w];
                float top = position_processed.ptr<float>()[b * 4 * grid_h * grid_w + 1 * grid_h * grid_w + h * grid_w + w];
                float right = position_processed.ptr<float>()[b * 4 * grid_h * grid_w + 2 * grid_h * grid_w + h * grid_w + w];
                float bottom = position_processed.ptr<float>()[b * 4 * grid_h * grid_w + 3 * grid_h * grid_w + h * grid_w + w];
                
                // 计算网格中心点
                float grid_x = static_cast<float>(w);
                float grid_y = static_cast<float>(h);
                
                // Python逻辑: box_xy = grid + 0.5 - position[:, 0:2, :, :]
                float x1 = (grid_x + 0.5f - left) * stride_w;
                float y1 = (grid_y + 0.5f - top) * stride_h;
                
                // Python逻辑: box_xy2 = grid + 0.5 + position[:, 2:4, :, :]
                float x2 = (grid_x + 0.5f + right) * stride_w;
                float y2 = (grid_y + 0.5f + bottom) * stride_h;
                
                // 存储xyxy格式
                xyxy.at<float>(anchor_idx, 0) = x1;
                xyxy.at<float>(anchor_idx, 1) = y1;
                xyxy.at<float>(anchor_idx, 2) = x2;
                xyxy.at<float>(anchor_idx, 3) = y2;
            }
        }
    }
    
    std::cout << "boxProcess输出形状: " << xyxy.size() << std::endl;
    return xyxy;
}

std::tuple<cv::Mat, cv::Mat, cv::Mat> YOLOv8Detector::postProcess(
    const std::vector<cv::Mat>& outputs) {
    /**
     * 后处理ONNX模型输出 - 完整实现
     * 模型输出结构: 3个分支，每个分支3个输出
     * - outputs[0,3,6]: 边界框预测 (1,64,H,W) 需要DFL处理
     * - outputs[1,4,7]: 类别概率 (1,6,H,W)  
     * - outputs[2,5,8]: 置信度 (1,1,H,W)
     */
    
    std::vector<cv::Mat> all_boxes, all_classes_conf, all_scores;
    int default_branch = 3;
    
    // 处理三个检测分支
    for (int i = 0; i < default_branch; ++i) {
        int box_idx = i * 3;      // 0, 3, 6
        int class_idx = i * 3 + 1; // 1, 4, 7
        int score_idx = i * 3 + 2; // 2, 5, 8
        
        std::cout << "处理分支 " << i << ": box=" << box_idx << ", class=" << class_idx << ", score=" << score_idx << std::endl;
        
        // 边界框处理
        cv::Mat boxes = boxProcess(outputs[box_idx]);
        all_boxes.push_back(boxes);
        
        // 类别概率和置信度直接展平
        cv::Mat classes_flat = spFlatten(outputs[class_idx]);
        cv::Mat scores_flat = spFlatten(outputs[score_idx]);
        
        all_classes_conf.push_back(classes_flat);
        all_scores.push_back(scores_flat);
    }
    
    // 连接所有分支的结果
    cv::Mat final_boxes, final_classes_conf, final_scores;
    cv::vconcat(all_boxes, final_boxes);
    cv::vconcat(all_classes_conf, final_classes_conf);
    cv::vconcat(all_scores, final_scores);
    
    std::cout << "合并后形状: boxes=" << final_boxes.size() << ", classes=" << final_classes_conf.size() << ", scores=" << final_scores.size() << std::endl;
    
    // 过滤和NMS
    auto [filtered_boxes, filtered_classes, filtered_scores] = 
        filterBoxes(final_boxes, final_scores, final_classes_conf);
    
    if (filtered_boxes.empty()) {
        return std::make_tuple(cv::Mat(), cv::Mat(), cv::Mat());
    }
    
    // NMS处理
    std::vector<cv::Mat> nboxes, nclasses, nscores;
    std::set<int> unique_classes;
    
    for (int i = 0; i < filtered_classes.rows; ++i) {
        unique_classes.insert(static_cast<int>(filtered_classes.at<float>(i)));
    }
    
    for (int c : unique_classes) {
        std::vector<int> class_indices;
        for (int i = 0; i < filtered_classes.rows; ++i) {
            if (static_cast<int>(filtered_classes.at<float>(i)) == c) {
                class_indices.push_back(i);
            }
        }
        
        if (class_indices.empty()) continue;
        
        cv::Mat class_boxes(class_indices.size(), 4, CV_32F);
        cv::Mat class_scores(class_indices.size(), 1, CV_32F);
        
        for (size_t i = 0; i < class_indices.size(); ++i) {
            int idx = class_indices[i];
            filtered_boxes.row(idx).copyTo(class_boxes.row(i));
            class_scores.at<float>(i) = filtered_scores.at<float>(idx);
        }
        
        std::vector<int> keep = nmsBoxes(class_boxes, class_scores);
        
        if (!keep.empty()) {
            cv::Mat kept_boxes(keep.size(), 4, CV_32F);
            cv::Mat kept_classes(keep.size(), 1, CV_32F);
            cv::Mat kept_scores(keep.size(), 1, CV_32F);
            
            for (size_t i = 0; i < keep.size(); ++i) {
                class_boxes.row(keep[i]).copyTo(kept_boxes.row(i));
                kept_classes.at<float>(i) = static_cast<float>(c);
                kept_scores.at<float>(i) = class_scores.at<float>(keep[i]);
            }
            
            nboxes.push_back(kept_boxes);
            nclasses.push_back(kept_classes);
            nscores.push_back(kept_scores);
        }
    }
    
    if (nboxes.empty()) {
        return std::make_tuple(cv::Mat(), cv::Mat(), cv::Mat());
    }
    
    cv::Mat result_boxes, result_classes, result_scores;
    cv::vconcat(nboxes, result_boxes);
    cv::vconcat(nclasses, result_classes);  
    cv::vconcat(nscores, result_scores);
    
    return std::make_tuple(result_boxes, result_classes, result_scores);
}

std::tuple<cv::Mat, cv::Mat, cv::Mat> YOLOv8Detector::filterBoxes(
    const cv::Mat& boxes, const cv::Mat& box_confidences, const cv::Mat& box_class_probs) {
    /**
     * 根据目标阈值过滤边界框 - 对照Python实现
     */
    // Python: box_confidences = box_confidences.reshape(-1)
    cv::Mat confidences = box_confidences.reshape(1, box_confidences.total());
    
    // Python: candidate, class_num = box_class_probs.shape
    int candidate = box_class_probs.rows;
    
    // Python: class_max_score = np.max(box_class_probs, axis=-1)
    // Python: classes = np.argmax(box_class_probs, axis=-1)
    cv::Mat class_max_scores(candidate, 1, CV_32F);
    cv::Mat classes(candidate, 1, CV_32F);
    
    for (int i = 0; i < candidate; ++i) {
        double min_val, max_val;
        cv::Point min_loc, max_loc;
        cv::minMaxLoc(box_class_probs.row(i), &min_val, &max_val, &min_loc, &max_loc);
        class_max_scores.at<float>(i) = static_cast<float>(max_val);
        classes.at<float>(i) = static_cast<float>(max_loc.x);
    }
    
    // Python: _class_pos = np.where(class_max_score * box_confidences >= OBJ_THRESH)
    // Python: scores = (class_max_score * box_confidences)[_class_pos]
    std::vector<int> valid_indices;
    for (int i = 0; i < candidate; ++i) {
        float score = class_max_scores.at<float>(i) * confidences.at<float>(i);
        if (score >= obj_thresh_) {
            valid_indices.push_back(i);
        }
    }
    
    if (valid_indices.empty()) {
        return std::make_tuple(cv::Mat(), cv::Mat(), cv::Mat());
    }
    
    // Python: boxes = boxes[_class_pos], classes = classes[_class_pos]
    cv::Mat filtered_boxes(valid_indices.size(), 4, CV_32F);
    cv::Mat filtered_classes(valid_indices.size(), 1, CV_32F);
    cv::Mat filtered_scores(valid_indices.size(), 1, CV_32F);
    
    for (size_t i = 0; i < valid_indices.size(); ++i) {
        int idx = valid_indices[i];
        boxes.row(idx).copyTo(filtered_boxes.row(i));
        filtered_classes.at<float>(i) = classes.at<float>(idx);
        filtered_scores.at<float>(i) = class_max_scores.at<float>(idx) * confidences.at<float>(idx);
    }
    
    return std::make_tuple(filtered_boxes, filtered_classes, filtered_scores);
}

std::vector<int> YOLOv8Detector::nmsBoxes(const cv::Mat& boxes, const cv::Mat& scores) {
    /**
     * 非极大值抑制
     */
    std::vector<cv::Rect> rects;  // 使用 cv::Rect (int) 而不是 cv::Rect2f (float)
    std::vector<float> scores_vec;
    std::vector<int> indices;
    
    for (int i = 0; i < boxes.rows; ++i) {
        float x1 = boxes.at<float>(i, 0);
        float y1 = boxes.at<float>(i, 1);
        float x2 = boxes.at<float>(i, 2);
        float y2 = boxes.at<float>(i, 3);
        
        // 转换为整数类型的Rect
        rects.emplace_back(static_cast<int>(x1), static_cast<int>(y1), 
                          static_cast<int>(x2 - x1), static_cast<int>(y2 - y1));
        scores_vec.push_back(scores.at<float>(i));
    }
    
    cv::dnn::NMSBoxes(rects, scores_vec, obj_thresh_, nms_thresh_, indices);
    
    return indices;
}

cv::Mat YOLOv8Detector::scaleBoxes(const cv::Size& img1_shape,
                                   const cv::Mat& boxes,
                                   const cv::Size& img0_shape,
                                   const std::pair<float, cv::Point2f>& ratio_pad) {
    /**
     * 将边界框从img1_shape缩放到img0_shape
     */
    (void)img1_shape;  // 避免未使用参数警告
    cv::Mat scaled_boxes = boxes.clone();
    float gain = ratio_pad.first;
    cv::Point2f pad = ratio_pad.second;
    
    // 减去填充
    for (int i = 0; i < scaled_boxes.rows; ++i) {
        scaled_boxes.at<float>(i, 0) -= pad.x; // x1
        scaled_boxes.at<float>(i, 2) -= pad.x; // x2
        scaled_boxes.at<float>(i, 1) -= pad.y; // y1
        scaled_boxes.at<float>(i, 3) -= pad.y; // y2
        
        // 缩放
        scaled_boxes.at<float>(i, 0) /= gain;
        scaled_boxes.at<float>(i, 1) /= gain;
        scaled_boxes.at<float>(i, 2) /= gain;
        scaled_boxes.at<float>(i, 3) /= gain;
    }
    
    clipBoxes(scaled_boxes, img0_shape);
    return scaled_boxes;
}

void YOLOv8Detector::clipBoxes(cv::Mat& boxes, const cv::Size& shape) {
    /**
     * 将边界框裁剪到图像尺寸范围内
     */
    for (int i = 0; i < boxes.rows; ++i) {
        boxes.at<float>(i, 0) = std::max(0.0f, std::min(static_cast<float>(shape.width), boxes.at<float>(i, 0)));
        boxes.at<float>(i, 1) = std::max(0.0f, std::min(static_cast<float>(shape.height), boxes.at<float>(i, 1)));
        boxes.at<float>(i, 2) = std::max(0.0f, std::min(static_cast<float>(shape.width), boxes.at<float>(i, 2)));
        boxes.at<float>(i, 3) = std::max(0.0f, std::min(static_cast<float>(shape.height), boxes.at<float>(i, 3)));
    }
}

cv::Mat YOLOv8Detector::spFlatten(const cv::Mat& input) {
    /**
     * 展平张量 - 对照Python的sp_flatten实现
     * Python: ch = _in.shape[1]
     * Python: _in = _in.transpose(0, 2, 3, 1)  
     * Python: return _in.reshape(-1, ch)
     */
    if (input.dims != 4) {
        std::cerr << "spFlatten: 输入必须是4维张量，当前维度: " << input.dims << std::endl;
        return cv::Mat();
    }
    
    int n = input.size[0];    // batch size
    int c = input.size[1];    // channels
    int h = input.size[2];    // height  
    int w = input.size[3];    // width
    
    // Python: _in.transpose(0, 2, 3, 1) -> (n, h, w, c)
    cv::Mat transposed = cv::Mat::zeros(n * h * w, c, CV_32F);
    
    for (int batch = 0; batch < n; ++batch) {
        for (int ch = 0; ch < c; ++ch) {
            for (int row = 0; row < h; ++row) {
                for (int col = 0; col < w; ++col) {
                    // 原始索引 (n, c, h, w)
                    int src_idx = batch * c * h * w + ch * h * w + row * w + col;
                    // 转置后索引 (n*h*w, c) 
                    int dst_row = batch * h * w + row * w + col;
                    int dst_col = ch;
                    
                    transposed.at<float>(dst_row, dst_col) = input.ptr<float>()[src_idx];
                }
            }
        }
    }
    
    return transposed;
}

} // namespace yolov8
